{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook's aim is to save you some mundane work of data preprocessing and extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# first let's provide some helper funtions\n",
    "def unpickle(file_path):\n",
    "    '''This function unpickles the training/testing file.'''\n",
    "    fo = open(file_path, 'rb')\n",
    "    raw_dict = pickle.load(fo, encoding='bytes')\n",
    "    fo.close()\n",
    "    return raw_dict\n",
    "\n",
    "def onehot_labels(labels):\n",
    "    '''This function turns numeric labels into one-hot encoding.'''\n",
    "    return np.eye(100)[labels]\n",
    "\n",
    "def get_proper_images(raw):\n",
    "    '''This function turns values of dict to numpy arrays of pixels'''\n",
    "    raw_float = np.array(raw, dtype=float) \n",
    "    images = raw_float.reshape([-1, 3, 32, 32])\n",
    "    images = images.transpose([0, 2, 3, 1])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps assume you downloaded test_cleaned and train_cleaned and placed in in the same directory as your notebook/script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both test_cleaned and train_cleaned are pickled Python dictionaries. Let's see wha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's unpickle and preprocess the data to traing the model.\n",
    "# note you don't have the labels of testing data.\n",
    "x_train = get_proper_images(unpickle('train_cleaned')['data'])\n",
    "y_train = onehot_labels(unpickle('train_cleaned')['fine_labels'])\n",
    "x_test = get_proper_images(unpickle('test_cleaned')['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is ready. I will show you how to generate your submission using simple Keras model as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are some constants for the model\n",
    "batch_size = 32\n",
    "num_classes = 100\n",
    "epochs = 1\n",
    "num_predictions = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define the actual model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "# let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 403s 8ms/step - loss: 3.9988 - acc: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd060f1ea58>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actually train the model\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 23s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# here we generate predictions of our model on testing set (unlabeled)\n",
    "predictions = model.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# now we need some Pandas magic to create the .csv submission file\n",
    "model_predictions = [np.argmax(predictions, axis=1)\n",
    "                     for _ in range(len(predictions))]\n",
    "filenames = unpickle('test_cleaned')['filenames']\n",
    "submission_df = pd.DataFrame({'filename': filenames,\n",
    "                             'predicted_class': model_predictions[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'volcano_s_000012.png'</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'woods_s_000412.png'</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'seal_s_001803.png'</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'mushroom_s_001755.png'</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'adriatic_sea_s_000653.png'</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  predicted_class\n",
       "0       b'volcano_s_000012.png'               49\n",
       "1         b'woods_s_000412.png'               80\n",
       "2          b'seal_s_001803.png'               90\n",
       "3      b'mushroom_s_001755.png'               54\n",
       "4  b'adriatic_sea_s_000653.png'               36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure columns are in right order and we are good to go!\n",
    "submission_df = submission_df.reindex(columns=['filename', 'predicted_class'])\n",
    "submission_df.to_csv('my_submission.csv', index=False)\n",
    "submission_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper format of submmission file is as presented above. First column must be 'filename' with name of the file (with this 'b' prefix for string) and second column must be 'predicted_class' with model's prediction for particular image with specified filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above cell wil produce my_submission.csv file which is to be sent to Kaggle for evaluation. The score you will get is the actual accuracy of your model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
